{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from string import ascii_letters\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "# !curl -O https://download.pytorch.org/tutorial/data.zip; unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch variables\n",
    "_ = torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Czech': tensor([0]),\n",
       " 'German': tensor([1]),\n",
       " 'Arabic': tensor([2]),\n",
       " 'Japanese': tensor([3]),\n",
       " 'Chinese': tensor([4]),\n",
       " 'Vietnamese': tensor([5]),\n",
       " 'Russian': tensor([6]),\n",
       " 'French': tensor([7]),\n",
       " 'Irish': tensor([8]),\n",
       " 'English': tensor([9]),\n",
       " 'Spanish': tensor([10]),\n",
       " 'Greek': tensor([11]),\n",
       " 'Italian': tensor([12]),\n",
       " 'Portuguese': tensor([13]),\n",
       " 'Scottish': tensor([14]),\n",
       " 'Dutch': tensor([15]),\n",
       " 'Korean': tensor([16]),\n",
       " 'Polish': tensor([17])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign int label to each language name\n",
    "data_dir = \"./data/names\"\n",
    "LANGUAGE_TO_LABEL = {\n",
    "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long) for i, file_name in enumerate(os.listdir(data_dir))\n",
    "}\n",
    "NUM_LANGUAGES = len(LANGUAGE_TO_LABEL)\n",
    "LANGUAGE_TO_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign label to each character in vocabulary\n",
    "CHAR_TO_IDX = {letter: i for i, letter in enumerate(ascii_letters + \" .,:;-'\")}\n",
    "NUM_LETTERS = len(CHAR_TO_IDX)\n",
    "NUM_LETTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_tensor(name, char_vocab_size=NUM_LETTERS, char_to_int_mapping=CHAR_TO_IDX):\n",
    "    \"\"\"Function to embed a name as a matrix, where each character in the name is a one-hot tensor\n",
    "    Each matrix also has a batch dimension of 1\"\"\"\n",
    "    emb = torch.zeros(len(name), 1, char_vocab_size)\n",
    "    for i, char in enumerate(name):\n",
    "        emb[i][0][char_to_int_mapping[char]] = 1\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_tensor = []\n",
    "target_langs = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, file)) as f:\n",
    "        language = file.split('.')[0]\n",
    "        names = [unidecode(line.rstrip()) for line in f]\n",
    "        for name in names:\n",
    "            try:\n",
    "                names_tensor.append(name_to_tensor(name))\n",
    "                target_langs.append(LANGUAGE_TO_LABEL[language])\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 18063\n",
      "Test dataset: 2007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(target_langs)),\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    stratify=target_langs\n",
    ")\n",
    "\n",
    "# Get train dataset\n",
    "train_dataset = [(names_tensor[i], target_langs[i]) for i in train_idx]\n",
    "\n",
    "# Get test dataset\n",
    "test_dataset = [(names_tensor[i], target_langs[i]) for i in test_idx]\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)}\")\n",
    "print(f\"Test dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple RNN model:\n",
    "# Takes in a single character & produces a prediction and a hidden state\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_to_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.in_to_output = nn.Linear(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = torch.sigmoid(self.in_to_hidden(combined))\n",
    "        output = self.in_to_output(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleRNN(NUM_LETTERS, hidden_size, NUM_LANGUAGES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [3000/18063], Loss: 2.2671\n",
      "Epoch [1/2], Step [6000/18063], Loss: 0.0082\n",
      "Epoch [1/2], Step [9000/18063], Loss: 1.0068\n",
      "Epoch [1/2], Step [12000/18063], Loss: 0.0156\n",
      "Epoch [1/2], Step [15000/18063], Loss: 0.0025\n",
      "Epoch [1/2], Step [18000/18063], Loss: 0.0220\n",
      "Epoch [2/2], Step [3000/18063], Loss: 0.0000\n",
      "Epoch [2/2], Step [6000/18063], Loss: 0.0006\n",
      "Epoch [2/2], Step [9000/18063], Loss: 0.0001\n",
      "Epoch [2/2], Step [12000/18063], Loss: 0.0000\n",
      "Epoch [2/2], Step [15000/18063], Loss: 0.0000\n",
      "Epoch [2/2], Step [18000/18063], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "print_interval = 3000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle data\n",
    "    random.shuffle(train_dataset)\n",
    "    \n",
    "    # Each batch contains just one name\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        # Reinit hidden state for each name\n",
    "        hidden_state = model.init_hidden()\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get prediction for name\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.6248%\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of model\n",
    "num_correct = 0\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += int(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_LANGUAGE = {label.item(): lang for lang, label in LANGUAGE_TO_LABEL.items()}\n",
    "\n",
    "def simple_rnn_predict(name):\n",
    "    model.eval()\n",
    "    name_tensor = name_to_tensor(name)\n",
    "    with torch.no_grad():\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name_tensor:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)    \n",
    "    return LABEL_TO_LANGUAGE[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeffrey: English\n",
      "Qin: Chinese\n",
      "Slaveya: Russian\n",
      "Michael: German\n",
      "Vladimir: Russian\n",
      "Stavrios: Greek\n"
     ]
    }
   ],
   "source": [
    "print(\"Jeffrey:\", simple_rnn_predict(\"Jeffrey\"))\n",
    "print(\"Qin:\", simple_rnn_predict(\"Qin\"))\n",
    "print(\"Slaveya:\", simple_rnn_predict(\"Slaveya\"))\n",
    "print(\"Michael:\", simple_rnn_predict(\"Michael\"))\n",
    "print(\"Vladimir:\", simple_rnn_predict(\"Vladimir\"))\n",
    "print(\"Stavrios:\", simple_rnn_predict(\"Stavrios\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=NUM_LETTERS, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, NUM_LANGUAGES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_state = self.init_hidden()\n",
    "        output, hidden_state = self.gru(x, hidden_state)\n",
    "        output = self.fc(output[-1])\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GRU model using same training hyperparameters\n",
    "model = GRUModel(num_layers=2, hidden_size=hidden_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [3000/18063], Loss: 0.1305\n",
      "Epoch [1/2], Step [6000/18063], Loss: 0.0002\n",
      "Epoch [1/2], Step [9000/18063], Loss: 3.5073\n",
      "Epoch [1/2], Step [12000/18063], Loss: 6.0814\n",
      "Epoch [1/2], Step [15000/18063], Loss: 0.0925\n",
      "Epoch [1/2], Step [18000/18063], Loss: 0.0021\n",
      "Epoch [2/2], Step [3000/18063], Loss: 0.2745\n",
      "Epoch [2/2], Step [6000/18063], Loss: 0.0004\n",
      "Epoch [2/2], Step [9000/18063], Loss: 0.0005\n",
      "Epoch [2/2], Step [12000/18063], Loss: 0.0001\n",
      "Epoch [2/2], Step [15000/18063], Loss: 0.0003\n",
      "Epoch [2/2], Step [18000/18063], Loss: 0.8954\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle data\n",
    "    random.shuffle(train_dataset)\n",
    "    \n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get predictions\n",
    "        output = model(name)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "         \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.7708%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        output = model(name)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += int(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_predict(name):\n",
    "    model.eval()\n",
    "    tensor_name = name_to_tensor(name)\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor_name)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "    model.train()\n",
    "    return LABEL_TO_LANGUAGE[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeffrey: English\n",
      "Qin: Chinese\n",
      "Slaveya: Italian\n",
      "Michael: Irish\n",
      "Vladimir: Russian\n",
      "Stavrios: Greek\n"
     ]
    }
   ],
   "source": [
    "print(\"Jeffrey:\", gru_predict(\"Jeffrey\"))\n",
    "print(\"Qin:\", gru_predict(\"Qin\"))\n",
    "print(\"Slaveya:\", gru_predict(\"Slaveya\"))\n",
    "print(\"Michael:\", gru_predict(\"Michael\"))\n",
    "print(\"Vladimir:\", gru_predict(\"Vladimir\"))\n",
    "print(\"Stavrios:\", gru_predict(\"Stavrios\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d192e28df793c6191c32d5d7f5519d67897f1b5f53fb3a3cb7ec8b5ebc9275a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
